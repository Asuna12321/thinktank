{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import os\n",
    "from config import DATA_PATH\n",
    "\n",
    "author_prefix_lst = ['#index', '#n', '#a', '#pc', '#cn', '#hi', '#pi', '#upi', '#t']\n",
    "author_cols = ['author_id', 'author_name', 'affiliations', 'published count', 'citation num',\n",
    "               'H-index', 'P-index of equal A', 'P-index of unequal A', 'interests']\n",
    "\n",
    "paper_prefix_lst = ['#index', '#*', '#@', '#t', '#c', '#%']\n",
    "paper_cols = ['id', 'title', 'authors_name', 'year', 'venue_name', 'references']\n",
    "\n",
    "JSON_KEYWORDS = ['id', 'authors', 'venue', 'year', 'keywords',\n",
    "                 'references', 'n_citation', 'doc_type']\n",
    "JSON_COLUMNS = ['id', 'author_id', 'author_org', 'venue_id', ' venue_name',\n",
    "                'year', 'keywords', 'references', 'n_cites', 'doc_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def parsejson2df(file, col_lst=JSON_KEYWORDS):\n",
    "    \"\"\" Parse & load json file to Dataframe.\n",
    "\n",
    "    Data at https://originalstatic.aminer.cn/misc/dblp.v12.7z\n",
    "    ** THIS FILE IS PRETTY LARGE (12GB when unzipped), the file is loaded by readline,\n",
    "    HOWEVER THE JSON DATA IS CONVERTED TO A SINGLE DATAFRAME, MAY REQUIRE LARGE MEMORY.\n",
    "\n",
    "    ETA 5hrs\n",
    "    \"\"\"\n",
    "\n",
    "    def parse(js):\n",
    "        processed_line = dict()\n",
    "        for col in set(col_lst).intersection(set(js.keys())):\n",
    "            # Only keywords in the list above are considered\n",
    "            # If more keywords are required, according read_in code should be added\n",
    "            if col == 'id':\n",
    "                processed_line['id'] = js['id']\n",
    "            elif col == 'authors':\n",
    "                authors = js['authors']\n",
    "                processed_line['authors_id'] = ';'.join([str(author.get('id', None))\n",
    "                                                         for author in authors if author.get('id', None)])\n",
    "                processed_line['authors_name'] = ';'.join([author.get('name', None)\n",
    "                                                           for author in authors if author.get('name', None)])\n",
    "                processed_line['authors_org'] = ';'.join([str(author.get('org', None))\n",
    "                                                          for author in authors if author.get('org', None)])\n",
    "            elif col == 'venue':\n",
    "                venue = js['venue']\n",
    "                processed_line['venue_id'] = venue.get('id', None)\n",
    "                processed_line['venue_name'] = venue.get('raw', None)\n",
    "            elif col == 'year':\n",
    "                processed_line['year'] = js['year']\n",
    "            elif col == 'keywords':\n",
    "                processed_line['keywords'] = ';'.join(js['keywords'])\n",
    "            elif col == 'references':\n",
    "                processed_line['references'] = ';'.join([str(r) for r in js['references']])\n",
    "            elif col == 'n_citation':\n",
    "                processed_line['n_cites'] = js['n_citation']\n",
    "            elif col == 'doc_type':\n",
    "                processed_line['doc_type'] = js['doc_type']\n",
    "        return processed_line\n",
    "\n",
    "    parsed_df = pd.DataFrame()\n",
    "    with open(file, encoding='utf-8') as f:\n",
    "        i = 0\n",
    "        while i < 10000:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.lstrip('[')\n",
    "            line = line.lstrip(',')\n",
    "            line = line.rstrip(']')\n",
    "            line = line.rstrip('\\n')\n",
    "            if line:\n",
    "                js = json.loads(line)\n",
    "                parsed_df = parsed_df.append(parse(js), ignore_index=True)\n",
    "            i += 1\n",
    "    # Change data type\n",
    "    parsed_df['id'] = parsed_df['id'].astype('int64')\n",
    "    parsed_df['year'] = parsed_df['year'].astype('int')\n",
    "    parsed_df['n_cites'] = parsed_df['n_cites'].astype('int')\n",
    "\n",
    "    return parsed_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.97438359260559\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dblp_paper_df = parsejson2df(os.path.join(DATA_PATH, 'dblp.v12.json'), col_lst=JSON_KEYWORDS)\n",
    "print(time.time() - start)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dblp_paper_df.to_csv(os.path.join(DATA_PATH, 'dblp_paper.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "with open((os.path.join(DATA_PATH, 'dblp.v12.json')), encoding='utf-8') as f:\n",
    "    i = 0\n",
    "    while i < 5:\n",
    "        line = f.readline()\n",
    "        i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mJSONDecodeError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-10-7782976c6c43>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mjs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mjson\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloads\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mline\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\__init__.py\u001B[0m in \u001B[0;36mloads\u001B[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[0;32m    346\u001B[0m             \u001B[0mparse_int\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mparse_float\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mand\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    347\u001B[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001B[1;32m--> 348\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_default_decoder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    349\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mcls\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    350\u001B[0m         \u001B[0mcls\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mJSONDecoder\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\decoder.py\u001B[0m in \u001B[0;36mdecode\u001B[1;34m(self, s, _w)\u001B[0m\n\u001B[0;32m    335\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    336\u001B[0m         \"\"\"\n\u001B[1;32m--> 337\u001B[1;33m         \u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mraw_decode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0midx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0m_w\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    338\u001B[0m         \u001B[0mend\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_w\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    339\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mend\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\json\\decoder.py\u001B[0m in \u001B[0;36mraw_decode\u001B[1;34m(self, s, idx)\u001B[0m\n\u001B[0;32m    353\u001B[0m             \u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mscan_once\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0midx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    354\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mStopIteration\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 355\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mJSONDecodeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Expecting value\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0ms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    356\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mend\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mJSONDecodeError\u001B[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "js = json.loads(line)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}